{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478ceb0a",
   "metadata": {},
   "source": [
    "# Diagnosing Underfitting vs Overfitting from Training Loss Curves\n",
    "\n",
    "## Objective\n",
    "Learn to diagnose model behavior when **validation data is unavailable** by:\n",
    "1. Interpreting training loss curve patterns\n",
    "2. Understanding what training loss alone can (and cannot) tell you\n",
    "3. Identifying additional signals that provide crucial diagnostic information\n",
    "\n",
    "## The Challenge\n",
    "Given only a training loss curve, we face ambiguity:\n",
    "- **Flat training loss** → Underfitting? Or already optimal?\n",
    "- **Decreasing training loss** → Learning well? Or memorizing?\n",
    "- **Low training loss** → Good fit? Or overfitting?\n",
    "\n",
    "## Key Questions\n",
    "1. What patterns in training loss suggest underfitting?\n",
    "2. What patterns suggest overfitting?\n",
    "3. What's ambiguous from training loss alone?\n",
    "4. What additional signals resolve ambiguities?\n",
    "\n",
    "## Approach\n",
    "1. Create synthetic datasets with known properties\n",
    "2. Train models of varying complexity\n",
    "3. Analyze training curves only\n",
    "4. Identify additional diagnostic signals\n",
    "5. Show how they resolve ambiguities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771506b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f93696",
   "metadata": {},
   "source": [
    "## Part 1: Synthetic Dataset with Known Complexity\n",
    "\n",
    "We'll create a regression dataset with:\n",
    "- **Known true function**: A moderately complex polynomial with some noise\n",
    "- **Controlled difficulty**: Adjustable signal-to-noise ratio\n",
    "- **Clear ground truth**: So we know when models are under/overfitting\n",
    "\n",
    "This lets us train models of different complexities and observe their training curves.\n",
    "\n",
    "### Dataset Properties:\n",
    "- **Input**: 1D features (easy to visualize)\n",
    "- **Output**: Continuous regression target\n",
    "- **True function**: 4th degree polynomial + sin component\n",
    "- **Noise level**: Moderate (allows both under and overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f63cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regression_data(n_samples=200, noise_level=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic regression data.\n",
    "    True function: y = 0.5*x^4 - 2*x^3 + x^2 + sin(3*x) + noise\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Generate input features\n",
    "    X = np.linspace(-2, 2, n_samples)\n",
    "    \n",
    "    # True underlying function (complex but learnable)\n",
    "    y_true = 0.5 * X**4 - 2 * X**3 + X**2 + np.sin(3 * X)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, noise_level, n_samples)\n",
    "    y = y_true + noise\n",
    "    \n",
    "    # Dense grid for visualization\n",
    "    X_grid = np.linspace(-2, 2, 500)\n",
    "    y_grid_true = 0.5 * X_grid**4 - 2 * X_grid**3 + X_grid**2 + np.sin(3 * X_grid)\n",
    "    \n",
    "    return X, y, y_true, X_grid, y_grid_true\n",
    "\n",
    "# Generate data\n",
    "X, y, y_true, X_grid, y_grid_true = generate_regression_data(n_samples=200, noise_level=0.3)\n",
    "\n",
    "# Split into train and validation (but we'll pretend val doesn't exist for main analysis)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "y_true_train = 0.5 * X_train**4 - 2 * X_train**3 + X_train**2 + np.sin(3 * X_train)\n",
    "y_true_val = 0.5 * X_val**4 - 2 * X_val**3 + X_val**2 + np.sin(3 * X_val)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Signal-to-noise ratio: {np.std(y_true) / 0.3:.2f}\")\n",
    "\n",
    "# Visualize the data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(X_grid, y_grid_true, 'g-', linewidth=3, label='True Function', alpha=0.8)\n",
    "ax.scatter(X_train, y_train, c='blue', s=50, alpha=0.6, \n",
    "           edgecolors='black', linewidth=0.5, label='Training Data')\n",
    "ax.scatter(X_val, y_val, c='red', s=50, alpha=0.6, marker='s',\n",
    "           edgecolors='black', linewidth=0.5, label='Validation Data (hidden)')\n",
    "\n",
    "ax.set_xlabel('X', fontsize=13)\n",
    "ax.set_ylabel('Y', fontsize=13)\n",
    "ax.set_title('Synthetic Regression Dataset\\n(Validation data exists but we\\'ll pretend it doesn\\'t)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49047d05",
   "metadata": {},
   "source": [
    "## Part 2: Train Models with Different Capacities\n",
    "\n",
    "We'll train neural networks with varying complexity:\n",
    "\n",
    "1. **Too Simple** (Underfitting): 1 hidden layer, 5 neurons\n",
    "2. **Just Right** (Good fit): 2 hidden layers, 20 neurons each\n",
    "3. **Too Complex** (Overfitting): 5 hidden layers, 100 neurons each\n",
    "\n",
    "For each model, we'll record:\n",
    "- Training loss at each epoch\n",
    "- Predictions on training data\n",
    "- (Secretly) validation loss for verification\n",
    "\n",
    "Then we'll analyze what can be inferred from training curves alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4000b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleNN(nn.Module):\n",
    "    \"\"\"Flexible neural network with configurable architecture\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1, hidden_dims=[20, 20], output_dim=1, dropout=0.0):\n",
    "        super(FlexibleNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Test the architectures\n",
    "models_config = {\n",
    "    'Underfitting (Too Simple)': [5],\n",
    "    'Good Fit (Just Right)': [20, 20],\n",
    "    'Overfitting (Too Complex)': [100, 100, 100, 100, 100]\n",
    "}\n",
    "\n",
    "print(\"Model Architectures:\")\n",
    "print(\"=\"*60)\n",
    "for name, hidden_dims in models_config.items():\n",
    "    model = FlexibleNN(hidden_dims=hidden_dims)\n",
    "    n_params = count_parameters(model)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Hidden layers: {hidden_dims}\")\n",
    "    print(f\"  Parameters: {n_params:,}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_detailed(model, X_train, y_train, X_val, y_val, \n",
    "                        epochs=500, lr=0.01, batch_size=32, verbose=True):\n",
    "    \"\"\"\n",
    "    Train model and log detailed metrics for analysis.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train_tensor = torch.FloatTensor(X_train.reshape(-1, 1))\n",
    "    y_train_tensor = torch.FloatTensor(y_train.reshape(-1, 1))\n",
    "    X_val_tensor = torch.FloatTensor(X_val.reshape(-1, 1))\n",
    "    y_val_tensor = torch.FloatTensor(y_val.reshape(-1, 1))\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Tracking metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],  # Secret - we won't use this for diagnosis\n",
    "        'train_predictions': [],\n",
    "        'gradient_norms': [],\n",
    "        'weight_norms': [],\n",
    "        'loss_decrease_rate': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Compute gradient norm\n",
    "            total_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** 0.5\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        \n",
    "        # Evaluation on full training set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_pred = model(X_train_tensor)\n",
    "            train_loss_full = criterion(train_pred, y_train_tensor).item()\n",
    "            \n",
    "            # Secret validation loss (for verification only)\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_loss = criterion(val_pred, y_val_tensor).item()\n",
    "        \n",
    "        # Compute weight norm\n",
    "        weight_norm = sum(p.norm().item() for p in model.parameters())\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss_full)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['gradient_norms'].append(total_norm)\n",
    "        history['weight_norms'].append(weight_norm)\n",
    "        \n",
    "        # Compute loss decrease rate\n",
    "        if epoch > 0:\n",
    "            decrease_rate = history['train_loss'][-2] - history['train_loss'][-1]\n",
    "            history['loss_decrease_rate'].append(decrease_rate)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: Train Loss={train_loss_full:.4f}, Val Loss={val_loss:.4f}\")\n",
    "    \n",
    "    # Final predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        history['final_train_predictions'] = model(X_train_tensor).numpy()\n",
    "        history['final_val_predictions'] = model(X_val_tensor).numpy()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Train all models\n",
    "print(\"Training models with different capacities...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, hidden_dims in models_config.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    model = FlexibleNN(hidden_dims=hidden_dims)\n",
    "    model, history = train_model_detailed(\n",
    "        model, X_train, y_train, X_val, y_val,\n",
    "        epochs=500, lr=0.001, batch_size=16, verbose=True\n",
    "    )\n",
    "    \n",
    "    trained_models[model_name] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'config': hidden_dims\n",
    "    }\n",
    "\n",
    "print(\"\\n✓ All models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa1fde",
   "metadata": {},
   "source": [
    "## Part 3: What Training Loss Curves Tell Us (and Don't Tell Us)\n",
    "\n",
    "Let's analyze the training curves WITHOUT looking at validation data.\n",
    "\n",
    "### Patterns to Look For:\n",
    "\n",
    "1. **Convergence Speed**\n",
    "   - Fast convergence → Might be too simple OR well-initialized\n",
    "   - Slow convergence → Might be too complex OR poor optimization\n",
    "\n",
    "2. **Final Loss Value**\n",
    "   - High plateau → Likely underfitting (can't fit training data)\n",
    "   - Very low loss → Good fit OR overfitting (ambiguous!)\n",
    "   - Zero loss → Definitely overfitting (memorization)\n",
    "\n",
    "3. **Loss Trajectory Shape**\n",
    "   - Smooth decrease → Normal learning\n",
    "   - Erratic/noisy → Unstable optimization or high capacity\n",
    "   - Quick drop then plateau → Hit model capacity\n",
    "\n",
    "4. **Late-Stage Behavior**\n",
    "   - Still decreasing → Not converged (keep training OR overfitting)\n",
    "   - Flat plateau → Converged (to what quality?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "colors = {'Underfitting (Too Simple)': 'blue', \n",
    "          'Good Fit (Just Right)': 'green',\n",
    "          'Overfitting (Too Complex)': 'red'}\n",
    "\n",
    "# Row 1: Training loss curves (what we see)\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    ax = axes[0, idx]\n",
    "    history = model_data['history']\n",
    "    \n",
    "    # Plot training loss only\n",
    "    epochs = range(len(history['train_loss']))\n",
    "    ax.plot(epochs, history['train_loss'], linewidth=2.5, \n",
    "            color=colors[model_name], label='Training Loss')\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('MSE Loss', fontsize=12)\n",
    "    ax.set_title(f'{model_name}\\nTraining Loss Curve', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # Add annotations about what we can infer\n",
    "    final_loss = history['train_loss'][-1]\n",
    "    ax.text(0.5, 0.95, f'Final Loss: {final_loss:.4f}', \n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
    "\n",
    "# Row 2: Training AND validation loss (ground truth - what we don't see)\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    ax = axes[1, idx]\n",
    "    history = model_data['history']\n",
    "    \n",
    "    epochs = range(len(history['train_loss']))\n",
    "    ax.plot(epochs, history['train_loss'], linewidth=2.5, \n",
    "            color=colors[model_name], label='Training Loss', alpha=0.7)\n",
    "    ax.plot(epochs, history['val_loss'], linewidth=2.5, linestyle='--',\n",
    "            color='orange', label='Validation Loss (hidden)', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('MSE Loss', fontsize=12)\n",
    "    ax.set_title(f'{model_name}\\nGround Truth (Train + Val)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # Calculate generalization gap\n",
    "    final_train_loss = history['train_loss'][-1]\n",
    "    final_val_loss = history['val_loss'][-1]\n",
    "    gap = final_val_loss - final_train_loss\n",
    "    \n",
    "    ax.text(0.5, 0.95, f'Gen Gap: {gap:.4f}', \n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', \n",
    "                     facecolor='red' if gap > 0.1 else 'lightgreen', \n",
    "                     alpha=0.7))\n",
    "\n",
    "plt.suptitle('Training Loss Analysis: What We See vs Ground Truth', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print observations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OBSERVATIONS FROM TRAINING CURVES ONLY:\")\n",
    "print(\"=\"*80)\n",
    "for model_name, model_data in trained_models.items():\n",
    "    history = model_data['history']\n",
    "    final_loss = history['train_loss'][-1]\n",
    "    initial_loss = history['train_loss'][0]\n",
    "    loss_reduction = initial_loss - final_loss\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Initial loss: {initial_loss:.4f}\")\n",
    "    print(f\"  Final loss: {final_loss:.4f}\")\n",
    "    print(f\"  Total reduction: {loss_reduction:.4f}\")\n",
    "    print(f\"  Final 10 epochs avg decrease: {np.mean(history['loss_decrease_rate'][-10:]):.6f}\")\n",
    "    \n",
    "    # Diagnosis based on training curve only\n",
    "    if final_loss > 0.1:\n",
    "        print(f\"  → Inference: HIGH final loss suggests UNDERFITTING\")\n",
    "    elif final_loss < 0.01:\n",
    "        print(f\"  → Inference: VERY LOW loss - could be good fit OR overfitting (AMBIGUOUS)\")\n",
    "    else:\n",
    "        print(f\"  → Inference: Moderate loss - uncertain (AMBIGUOUS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa05f4d",
   "metadata": {},
   "source": [
    "## Part 4: The Ambiguity Problem\n",
    "\n",
    "### What Training Loss CANNOT Tell Us:\n",
    "\n",
    "Even with the training curves above, we face ambiguity:\n",
    "\n",
    "1. **Low training loss** (0.01):\n",
    "   - ✅ Could mean: Model fits the true pattern well\n",
    "   - ❌ Could mean: Model memorizes noise and will generalize poorly\n",
    "   \n",
    "2. **Plateaued training loss** (0.15):\n",
    "   - ✅ Could mean: Model converged to best possible fit\n",
    "   - ❌ Could mean: Model lacks capacity to fit the pattern\n",
    "\n",
    "3. **Still-decreasing loss**:\n",
    "   - ✅ Could mean: Model is still learning useful patterns\n",
    "   - ❌ Could mean: Model is starting to memorize individual points\n",
    "\n",
    "### We Need Additional Signals!\n",
    "\n",
    "Let's identify signals that resolve these ambiguities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee46764",
   "metadata": {},
   "source": [
    "## Part 5: Additional Diagnostic Signals\n",
    "\n",
    "When validation data is unavailable, request these signals:\n",
    "\n",
    "### 1. **Gradient Norms**\n",
    "- **Vanishing gradients** → Underfitting (optimization issue)\n",
    "- **Exploding gradients** → Poor initialization or instability\n",
    "- **Healthy gradients** → Normal learning\n",
    "\n",
    "### 2. **Weight Norms**\n",
    "- **Growing weights** → Potential overfitting\n",
    "- **Stable weights** → Good regularization\n",
    "- **Small weights** → Potential underfitting\n",
    "\n",
    "### 3. **Learning Curves** (vary training set size)\n",
    "- **Both train/val high** → Underfitting\n",
    "- **Train low, val high** → Overfitting\n",
    "- **Both converging** → Good fit\n",
    "\n",
    "### 4. **Model Predictions Visualization**\n",
    "- **Smooth curve** → Generalizable pattern\n",
    "- **Wiggy curve** → Memorizing noise\n",
    "- **Flat prediction** → Underfitting\n",
    "\n",
    "### 5. **Training with Different Data Subsets**\n",
    "- **Consistent performance** → Learning patterns\n",
    "- **Inconsistent performance** → Memorizing specific examples\n",
    "\n",
    "### 6. **Noise Sensitivity**\n",
    "- **Performance robust to noise** → Good generalization\n",
    "- **Performance degrades with noise** → Overfitting\n",
    "\n",
    "### 7. **Early Stopping Analysis**\n",
    "- If we had checkpoints, which epoch would we pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1773d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    ax = axes[idx]\n",
    "    history = model_data['history']\n",
    "    \n",
    "    epochs = range(len(history['gradient_norms']))\n",
    "    ax.plot(epochs, history['gradient_norms'], linewidth=2, \n",
    "            color=colors[model_name], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Gradient Norm', fontsize=12)\n",
    "    ax.set_title(f'{model_name}\\nGradient Norms Over Training', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # Analyze gradient behavior\n",
    "    final_grad = history['gradient_norms'][-1]\n",
    "    avg_early_grad = np.mean(history['gradient_norms'][:50])\n",
    "    \n",
    "    if final_grad < 1e-4:\n",
    "        diagnosis = \"Vanishing gradients\\n→ May indicate underfitting\"\n",
    "        color = 'red'\n",
    "    elif final_grad > 1e2:\n",
    "        diagnosis = \"Large gradients\\n→ Still learning or unstable\"\n",
    "        color = 'orange'\n",
    "    else:\n",
    "        diagnosis = \"Normal gradient range\\n→ Healthy optimization\"\n",
    "        color = 'lightgreen'\n",
    "    \n",
    "    ax.text(0.5, 0.95, diagnosis,\n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.7))\n",
    "\n",
    "plt.suptitle('Additional Signal 1: Gradient Norms', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGradient Analysis:\")\n",
    "print(\"=\"*80)\n",
    "for model_name, model_data in trained_models.items():\n",
    "    history = model_data['history']\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Final gradient norm: {history['gradient_norms'][-1]:.6f}\")\n",
    "    print(f\"  Average gradient (last 50 epochs): {np.mean(history['gradient_norms'][-50:]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    ax = axes[idx]\n",
    "    history = model_data['history']\n",
    "    \n",
    "    epochs = range(len(history['weight_norms']))\n",
    "    ax.plot(epochs, history['weight_norms'], linewidth=2, \n",
    "            color=colors[model_name], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Total Weight Norm', fontsize=12)\n",
    "    ax.set_title(f'{model_name}\\nWeight Norms Over Training', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Analyze weight growth\n",
    "    initial_weight = history['weight_norms'][0]\n",
    "    final_weight = history['weight_norms'][-1]\n",
    "    growth_rate = (final_weight - initial_weight) / initial_weight\n",
    "    \n",
    "    if growth_rate > 0.5:\n",
    "        diagnosis = f\"Weights grew {growth_rate*100:.1f}%\\n→ Potential overfitting\"\n",
    "        color = 'red'\n",
    "    elif growth_rate < -0.2:\n",
    "        diagnosis = f\"Weights decreased\\n→ Strong regularization\"\n",
    "        color = 'yellow'\n",
    "    else:\n",
    "        diagnosis = f\"Weights stable\\n→ Good training dynamics\"\n",
    "        color = 'lightgreen'\n",
    "    \n",
    "    ax.text(0.5, 0.95, diagnosis,\n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.7))\n",
    "\n",
    "plt.suptitle('Additional Signal 2: Weight Norms', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nWeight Norm Analysis:\")\n",
    "print(\"=\"*80)\n",
    "for model_name, model_data in trained_models.items():\n",
    "    history = model_data['history']\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Initial weight norm: {history['weight_norms'][0]:.2f}\")\n",
    "    print(f\"  Final weight norm: {history['weight_norms'][-1]:.2f}\")\n",
    "    print(f\"  Growth: {((history['weight_norms'][-1] - history['weight_norms'][0])/history['weight_norms'][0]*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41201036",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get predictions\n",
    "    model = model_data['model']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_grid_tensor = torch.FloatTensor(X_grid.reshape(-1, 1))\n",
    "        y_pred_grid = model(X_grid_tensor).numpy().flatten()\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(X_grid, y_grid_true, 'g-', linewidth=3, label='True Function', alpha=0.7)\n",
    "    ax.plot(X_grid, y_pred_grid, 'r-', linewidth=2.5, label='Predicted Function', alpha=0.8)\n",
    "    ax.scatter(X_train, y_train, c='blue', s=40, alpha=0.5, \n",
    "               edgecolors='black', linewidth=0.5, label='Training Data')\n",
    "    \n",
    "    ax.set_xlabel('X', fontsize=12)\n",
    "    ax.set_ylabel('Y', fontsize=12)\n",
    "    ax.set_title(f'{model_name}\\nLearned Function', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Analyze prediction smoothness\n",
    "    # Calculate second derivative (curvature) as proxy for wiggliness\n",
    "    pred_curvature = np.abs(np.gradient(np.gradient(y_pred_grid)))\n",
    "    avg_curvature = np.mean(pred_curvature)\n",
    "    \n",
    "    true_curvature = np.abs(np.gradient(np.gradient(y_grid_true)))\n",
    "    true_avg_curvature = np.mean(true_curvature)\n",
    "    \n",
    "    curvature_ratio = avg_curvature / true_avg_curvature\n",
    "    \n",
    "    if curvature_ratio < 0.5:\n",
    "        diagnosis = \"Too smooth\\n→ Underfitting\"\n",
    "        color_box = 'yellow'\n",
    "    elif curvature_ratio > 2.0:\n",
    "        diagnosis = \"Too wiggly\\n→ Overfitting\"\n",
    "        color_box = 'red'\n",
    "    else:\n",
    "        diagnosis = \"Good smoothness\\n→ Good fit\"\n",
    "        color_box = 'lightgreen'\n",
    "    \n",
    "    ax.text(0.5, 0.95, diagnosis,\n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor=color_box, alpha=0.7))\n",
    "\n",
    "plt.suptitle('Additional Signal 3: Model Predictions (Function Shape)', \n",
    "             fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPrediction Analysis:\")\n",
    "print(\"=\"*80)\n",
    "for model_name, model_data in trained_models.items():\n",
    "    model = model_data['model']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_grid_tensor = torch.FloatTensor(X_grid.reshape(-1, 1))\n",
    "        y_pred_grid = model(X_grid_tensor).numpy().flatten()\n",
    "    \n",
    "    # Calculate fit quality on training data\n",
    "    X_train_tensor = torch.FloatTensor(X_train.reshape(-1, 1))\n",
    "    y_pred_train = model(X_train_tensor).numpy().flatten()\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Training MSE: {train_mse:.4f}\")\n",
    "    print(f\"  Training MAE: {train_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6bc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
